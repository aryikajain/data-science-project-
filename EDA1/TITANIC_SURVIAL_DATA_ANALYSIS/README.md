# Titanic Survival Data Analysis

### Project Overview  
The **Titanic Survival Analysis** explores which factors most strongly influenced a passengerâ€™s chance of survival in the tragic 1912 disaster.  
Using data analysis, visualization, and feature engineering, this project aims to uncover **patterns and insights** in passenger demographics, ticket class, fare, and other variables.

---

###  Objectives  
- Understand the dataset structure and features.  
- Handle **missing values** and **outliers** effectively.  
- Explore how **gender, age, and passenger class** affected survival.  
- Perform **EDA (Exploratory Data Analysis)** and create **visual stories**.  
- Learn **feature encoding**, **correlation analysis**, and **data cleaning**.  
- (Optional) Build a **basic ML model** to predict survival outcomes.

---

###  Concepts Covered  
| Concept | Description |
|----------|--------------|
| **Missing Value Handling** | Using `fillna`, `dropna`, median/mode replacement |
| **Outlier Detection** | Using boxplots to identify extreme values |
| **Encoding Categorical Data** | Label & one-hot encoding for model readiness |
| **Correlation & Heatmap** | Finding relationships between features |
| **Visualization & Storytelling** | Using Seaborn & Matplotlib to uncover insights |
| **Feature Engineering** | Creating new features like `FamilySize` |

---

###  Key Questions Explored  
- Which features most affect survival?  
- Does **gender** or **passenger class** matter more?  
- How does **fare** influence survival probability?  
- What age groups were more likely to survive?  

---

#### Dataset  
- **Source:** [Kaggle Titanic Dataset](https://www.kaggle.com/c/titanic/data)  
- **Files Used:**  
  - `titanic.csv` (combined training and test data for EDA)  

---

### Tools & Libraries  
```
Python 3.x  
pandas  
numpy  
matplotlib  
seaborn  
scikit-learn (optional for modeling)
```

---

### ğŸ“‚ Project Structure  
```
Titanic-Survival-Analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ titanic.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ titanic_analysis.ipynb
â”‚
â”œâ”€â”€ visuals/
â”‚   â”œâ”€â”€ survival_by_gender.png
â”‚   â”œâ”€â”€ class_vs_survival.png
â”‚   â””â”€â”€ heatmap.png
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ clean_and_encode.py
â”‚
â”œâ”€â”€ README.md
```

---

###  EDA Insights Summary  
| Insight | Observation |
|----------|--------------|
| **Gender** | Females had a much higher survival rate than males. |
| **Class** | Passengers in 1st class survived the most. |
| **Age** | Younger passengers had better chances of survival. |
| **Fare** | Higher fares correlated with higher survival probability. |
| **Family Size** | Moderate family size (2â€“4 members) had better survival. |

---

###  Steps Performed  
1. Loaded dataset & explored structure.  
2. Handled missing data (Age, Embarked).  
3. Detected and examined outliers in Fare.  
4. Encoded categorical columns (Sex, Embarked).  
5. Analyzed feature correlations.  
6. Created visualizations for storytelling.  
7. (Optional) Built a Logistic Regression model to test predictability.  

---

### Example Visuals  
- **Gender vs Survival Countplot**  
- **Pclass vs Survival Rate**  
- **Age & Fare Distribution**  
- **Correlation Heatmap**

---

###  Learnings  
- Gained understanding of **real-world data cleaning** techniques.  
- Learned to use **EDA and visualization** to tell a story with data.  
- Discovered how small preprocessing steps impact **model performance**.  
- Understood how to connect **insights â†’ business or social meaning**.

---

### ğŸ§© Optional: Simple Model Accuracy Example
```python
Logistic Regression Accuracy: 0.79
```
*(Model built using basic cleaned features â€” not tuned)*

---

###  Future Improvements  
- Feature scaling & model tuning  
- Adding decision tree or random forest models  
- Comparing ML performance metrics  

---

###  Author  
**Aryika Jain**  
ğŸ“ Data Science & ML Enthusiast | Exploring AI, NLP & EDA  
ğŸ”— [GitHub Profile](https://github.com/aryikajain)
